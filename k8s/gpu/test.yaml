apiVersion: apps/v1beta2
kind: Deployment
metadata:
  name: test9
  labels:
    app: dev-situation
    chart: dev-situation-0.1.0
    release: test9
    heritage: Tiller
  namespace: intelligence-service-lab
spec:
  replicas: 1
  selector:
    matchLabels:
      app: dev-situation
      release: test9
  template:
    metadata:
      labels:
        app: dev-situation
        release: test9
    spec:
      containers:
        - name: dev-situation
          image: "registry.bst-1.cns.bstjpc.com:5000/bvlc/caffe-sshd:gpu"
          imagePullPolicy: Always
          ports:
          - containerPort: 22
          - containerPort: 8888
          resources:
            limits:
              cpu: "500m"
              memory: 1Gi
              nvidia.com/gpu-k20m: 0
          volumeMounts:
          - mountPath: /root/.ssh_config
            name: ssh-key
          - mountPath: /data
            name: data-pv
          - mountPath: /common-data
            name: common-data-pv
          - mountPath: /usr/local/nvidia/bin
            name: bin
          - mountPath: /usr/local/nvidia/lib
            name: lib

      nodeSelector:
        kubernetes.io/hostname: k8s-n2
#        usage: dev

      volumes:
      - name: ssh-key
        configMap:
          name: hongchao-ma
          items:
          - key: ssh_public_key
            path: authorized_keys
      - name: data-pv
        flexVolume:
          driver: srcb/cephfs
          options:
            monitors: ceph-mon1:6789,ceph-mon2:6789,ceph-mon3:6789,ceph-mon4:6789,ceph-mon5:6789
            share: '/hongchao.ma'
            authid: admin
            mds: Data_Intelligence_Labfs
            keyring: AQDeUgJbJgwNMhAAnzeW5LwQSwqMyWs7Zvl5cQ==
      - name: common-data-pv
        persistentVolumeClaim:
          claimName: intelligence-service-lab-common
      - hostPath:
          path: /usr/lib/nvidia-384/bin
        name: bin
      - hostPath:
          path: /usr/lib/nvidia-384
        name: lib
